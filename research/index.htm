<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="author" content="MARS">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name=keywords content="Mang Ye", "Ye Mang", "叶茫", "WHU", "Wuhan University", "武汉大学", "MARS", "marswhu", "MARS WHU">

  <title>Research</title>

  <link href="../static/bootstrap/css/bootstrap.css" rel="stylesheet">
  <link href="../static/xin.css" rel="stylesheet">

</head>

<body>

  <nav class="navbar navbar-inverse navbar-static-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <!-- <span class="navbar-brand">
          <font color="#ffffff">MARS</a></font>
        </span> -->
      </div>
      <div class="navbar-collapse collapse">
        <ul class="nav navbar-nav">
          <li><a href="../index.html">Home</a></li>
          <li><a href="../news/index.html">News</a></li>
          <li class="active"><a href="/index.htm">Research</a></li>
          <li><a href="../publications/index.htm">Publications</a></li>
          <li><a href="../contact/index.htm">Contact</a></li>              
      </ul>
      </div>
    </div>
  </nav>

  <div class="container">
    
  <hr>
  <h2 class="red">Research Interests</h2>
    <p>
Currently, our interests lie broadly in  <b><i>computer vision</i></b>, pattern recognition and  machine learning.
<br><br/>
We have long been committed to theoretical research and method innovation in the frontier field of computer vision, focusing on in-depth research on core tasks 
such as person retrieval and re-identification, object detection, and action recognition in complex scenes. 
<br><br/>
In response to key challenges in practical applications, we systematically explored the theoretical framework and implementation methods of domain adaptation and domain generalization, 
and are committed to building an efficient and robust visual analysis system. Based on machine learning technology, we continue to develop a series of innovative algorithms and practical tools, 
aiming to provide reliable technical support and solutions for intelligent security, social public safety and other fields.
  </p>

 <h2>Major Grants</h2>
  <p style="color: black; style= font-size: 25px; font-weight: bold;">&#9632; &nbsp 江苏省自然科学基金优秀青年基金，BK20220107，社会公共安全行人视觉特征学习与重识别，2022-07至2025-06，在研，主持</p>
  <p style="color: black; style= font-size: 25px; font-weight: bold;">&#9632; &nbsp 国家自然科学基金面上项目，62172231，多场景跨视域视频监控行人重识别研究，2022-01至2025-12，在研，主持</p>
  <p style="color: black; style= font-size: 25px; font-weight: bold;">&#9632; &nbsp 国家自然科学基金青年基金项目，61806099，基于稀疏表示分类准则的领域适应特征学习方法研究，2019-01至2021-12，结题，主持</p>
  <p style="color: black; style= font-size: 25px; font-weight: bold;">&#9632; &nbsp 江苏省自然科学基金青年基金项目，BK20180790，面向领域适应的特征提取与字典学习方法研究，2018-07至2021-06，结题，主持</p>
  <p style="color: black; style= font-size: 25px; font-weight: bold;">&#9632; &nbsp 江苏省高校自然科学研究面上项目，18KJB520033F，基于字典学习理论的领域适应特征学习算法研究，2018-09至2020-08，结题</p>
  <p style="color: black; style= font-size: 25px; font-weight: bold;">&#9632; &nbsp 国家自然科学基金联合基金重点支持类项目，U22B2056，数据与知识驱动的无人自主多源目标与最优驾驶行为协同识别方法，2023-01至2026-12，参与</p>
 <p style="color: black; style= font-size: 25px; font-weight: bold;">&#9632; &nbsp 大连理工大学社会计算与认知智能教育部重点实验室开放课题，SCCI2024YB04，多源跨模态社会公共安全视觉智能感知计算，2025-01至2026-12，在研，主持</p>
 <p style="color: black; style= font-size: 25px; font-weight: bold;">&#9632; &nbsp 江苏省社会安全图像与视频理解重点实验室开放课题，多源跨平台视频监控行人重识别方法研究，2023-01至2024-12，结题，主持</p>
<p style="color: black; style= font-size: 25px; font-weight: bold;">&#9632; &nbsp 江苏省应用数学（南京信息工程大学）中心开放课题，AI智能写作系统，2024-01至2025-12，在研，主持</p>
<p style="color: black; style= font-size: 25px; font-weight: bold;">&#9632; &nbsp 无锡市产业创新研究院先导技术预研项目，作业人员行为视觉智能分析与异常预警，2024-07至2026-06，主要参与</p>
    

    
<!--<p>这是一个实心方形：&#9632;</span></p>-->


    
    <!-- <h3>Software Packages</h3>


    <h4>Re-ID Survey with AGW Baseline:&nbsp;<a href="https://github.com/mangye16/ReID-Survey">Code</a> </h4>
    <ul>
      <li>A comprehensive survey with in-depth analysis for closed- and open-world person Re-ID in recent years (2016-2020).</li>
      <li>A new evaluation metric, namely mean Inverse Negative Penalty (mINP), which measures the ability to find the hardest correct match.</li>
      <li>A new AGW baseline with non-local Attention block, Generalized mean pooling and Weighted regularization triplet. It acheieves competitive performance on FOUR challenging Re-ID tasks, including single-modality image-based Re-ID, video-based Re-ID, Partial Re-ID and cross-modality Re-ID.</li>
      <li>Paper: "Deep Learning for Person Re-identification: A Survey and Outlook", TPAMI 2021. <a href="https://arxiv.org/abs/2001.04193v2">PDF</a></li>
    </ul>
    
    <h4>Cross-modality Visible-Infrared Re-ID Baseline:&nbsp;<a href="https://github.com/mangye16/Cross-Modal-Re-ID-baseline">Code</a> </h4>
    <ul>
      <li> Cross-Modality Person Re-Identification (Visible Infrared Re-ID) Baseline on RegDB and SYSU-MM01 datasets</li>
      <li> Channel augmentation with multi-modality joint training</li>
      <li> Two-stream network with AGW baseline for cross-modality ReID</li>  
      <li> Paper: "Channel Augmented Joint Learning for Visible-Infrared Recognition", ICCV 2021.<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Ye_Channel_Augmented_Joint_Learning_for_Visible-Infrared_Recognition_ICCV_2021_paper.pdf">PDF</a></li>
      <li>Paper: "Deep Learning for Person Re-identification: A Survey and Outlook", TPAMI 2021. <a href="https://arxiv.org/abs/2001.04193v2">PDF</a></li>
      <li> Paper: "Bi-directional Center-Constrained Top-Ranking for Visible Thermal Person Re-Identification", TIFS 2019. <a href="https://ieeexplore.ieee.org/document/8732420">PDF</a></li>
    </ul>
    
    <h4>Unsupervised Deep Learning:&nbsp;<a href="https://github.com/mangye16/Unsupervised_Embedding_Learning">Code</a></h4>
    <ul>
      <li> Instance discrimination: Positive concentration (data augmentation invariance) and negative separation (instance spread-out) </li>
      <li> "Real-time" instance feature softmax embedding, faster speed and higher accuracy </li>
      <li> Positive supervision augmentation and negative supervision augmentation at feature level </li>
      <li> Paper: "Unsupervised Embedding Learning via Invariant and Spreading Instance Feature", CVPR 2019. <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Ye_Unsupervised_Embedding_Learning_via_Invariant_and_Spreading_Instance_Feature_CVPR_2019_paper.pdf">PDF</a></li>
      <li> Paper: "Augmentation Invariant and Instance Spreading Feature for Softmax Embedding", TPAMI 2020. <a href="https://ieeexplore.ieee.org/document/9154587">PDF</a></li>
    </ul>

    <h4>WePerson Dataset:&nbsp;<a href="https://github.com/lihe404/WePerson">Code</a></h4>
    <ul>
      <li> This is the first large-scale synthesized Re-ID dataset that considers various weather effects. </li>
      <li> To date, this is the largest virtual dataset for person images.</li>
      <li> Paper: "WePerson: Learning a Generalized Re-identification Model from All-weather Virtual Data", ACM MM, 2021. <a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475455">PDF</a></li>
    </ul>


    <h4>Robust Deep Learning with Label Noise:&nbsp;<a href="https://github.com/mangye16/ReID-Label-Noise">Code</a></h4>
    <ul>
      <li> Robust deep learning under label noise (limited samples for each identity)</li>
      <li> Collaborative refining person re-identification model under label noise</li>
      <li> Online refining with hard instance re-weighting</li>
      <li> Paper: "PurifyNet: A Robust Person Re-identification Model with Noisy Labels", IEEE TIFS, 2020. <a href="https://ieeexplore.ieee.org/document/8976262">PDF</a></li>
      <li> Paper: "Collaborative Refining for Person Re-Identification with Label Noise", IEEE TIP, 2021.</li>
    </ul>


    <h3>Research Fundings</h3>
    <h4>主持科研项目：</h4>
    <ul>
      <li>2022.01-2024.12 基于无监督学习的监控目标检索关键技术研究 湖北省重点研发计划 100万</li>
      <li>2022.01-2025.12 面向复杂多变场景的行人重识别关键技术研究 国家自然科学基金（面上项目） 59万</li>
      <li>2021.02-2022.12 目标检测、跟踪与识别 中国科协青年人才托举项目 45万 </li>
      <li>2020.12-2021.11 开放环境下视觉学习理论及其应用 首届中国人工智能学会-华为 MindSpore学术奖励基金（B类） 18万 </li>
      <li>2021.11-2022.10 基于异构联邦学习的智能数据分类算法与框架  CCF-绿盟科技“鲲鹏”科研基金 8万</li>
      <li>2021.12-2022.11 开放场景下的监控目标检索关键技术研究 中国人工智能学会-华为 MindSpore学术奖励基金（B类） 18万 </li>
    </ul>

    <h3>Terms of Releasing Implementation: </h3>
    <p> Software provided here is for personal research purposes only. Redistribution and commercial usage are not
      permitted. Feedback, applications, and further development are welcome. Contact yemang AT whu.edu.cn for bugs and
      collaborations. All rights of the implementation are reserved by the authors.</p> -->


  </div>


  <script src="../static/jquery.js"></script>
  <script src="../static/bootstrap/js/bootstrap.js"></script>
</body>

</html>
