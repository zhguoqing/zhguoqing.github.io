<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="author" content="MARS">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name=keywords content="Mang Ye", "Ye Mang", "叶茫", "WHU", "Wuhan University", "武汉大学", "MARS", "marswhu", "MARS WHU">

  <title>Projects</title>

  <link href="../static/bootstrap/css/bootstrap.css" rel="stylesheet">
  <link href="../static/xin.css" rel="stylesheet">

</head>

<body>

  <nav class="navbar navbar-inverse navbar-static-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <span class="navbar-brand">
          <font color="#ffffff">MARS</a></font>
        </span>
      </div>
      <div class="navbar-collapse collapse">
        <ul class="nav navbar-nav">
          <li><a href="../index.html">Home</a></li>
          <li><a href="../publications/index.htm"> Publications </a></li>
          <li class="active"><a href="index.htm"> Projects </a></li>
          <li><a href="../team/index.htm">Team</a></li>
          <li><a href="../teaching/index.htm">Teaching</a></li>
          <li><a href="../service/index.htm">Service</a></li>
        </ul>
      </div>
    </div>
  </nav>

  <div class="container">

    <h3>Software Packages</h3>


    <h4>Re-ID Survey with AGW Baseline:&nbsp;<a href="https://github.com/mangye16/ReID-Survey">Code</a> </h4>
    <ul>
      <li>A comprehensive survey with in-depth analysis for closed- and open-world person Re-ID in recent years (2016-2020).</li>
      <li>A new evaluation metric, namely mean Inverse Negative Penalty (mINP), which measures the ability to find the hardest correct match.</li>
      <li>A new AGW baseline with non-local Attention block, Generalized mean pooling and Weighted regularization triplet. It acheieves competitive performance on FOUR challenging Re-ID tasks, including single-modality image-based Re-ID, video-based Re-ID, Partial Re-ID and cross-modality Re-ID.</li>
      <li>Paper: "Deep Learning for Person Re-identification: A Survey and Outlook", TPAMI 2021. <a href="https://arxiv.org/abs/2001.04193v2">PDF</a></li>
    </ul>
    
    <h4>Cross-modality Visible-Infrared Re-ID Baseline:&nbsp;<a href="https://github.com/mangye16/Cross-Modal-Re-ID-baseline">Code</a> </h4>
    <ul>
      <li> Cross-Modality Person Re-Identification (Visible Infrared Re-ID) Baseline on RegDB and SYSU-MM01 datasets</li>
      <li> Channel augmentation with multi-modality joint training</li>
      <li> Two-stream network with AGW baseline for cross-modality ReID</li>  
      <li> Paper: "Channel Augmented Joint Learning for Visible-Infrared Recognition", ICCV 2021.<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Ye_Channel_Augmented_Joint_Learning_for_Visible-Infrared_Recognition_ICCV_2021_paper.pdf">PDF</a></li>
      <li>Paper: "Deep Learning for Person Re-identification: A Survey and Outlook", TPAMI 2021. <a href="https://arxiv.org/abs/2001.04193v2">PDF</a></li>
      <li> Paper: "Bi-directional Center-Constrained Top-Ranking for Visible Thermal Person Re-Identification", TIFS 2019. <a href="https://ieeexplore.ieee.org/document/8732420">PDF</a></li>
    </ul>
    
    <h4>Unsupervised Deep Learning:&nbsp;<a href="https://github.com/mangye16/Unsupervised_Embedding_Learning">Code</a></h4>
    <ul>
      <li> Instance discrimination: Positive concentration (data augmentation invariance) and negative separation (instance spread-out) </li>
      <li> "Real-time" instance feature softmax embedding, faster speed and higher accuracy </li>
      <li> Positive supervision augmentation and negative supervision augmentation at feature level </li>
      <li> Paper: "Unsupervised Embedding Learning via Invariant and Spreading Instance Feature", CVPR 2019. <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Ye_Unsupervised_Embedding_Learning_via_Invariant_and_Spreading_Instance_Feature_CVPR_2019_paper.pdf">PDF</a></li>
      <li> Paper: "Augmentation Invariant and Instance Spreading Feature for Softmax Embedding", TPAMI 2020. <a href="https://ieeexplore.ieee.org/document/9154587">PDF</a></li>
    </ul>

    <h4>WePerson Dataset:&nbsp;<a href="https://github.com/lihe404/WePerson">Code</a></h4>
    <ul>
      <li> This is the first large-scale synthesized Re-ID dataset that considers various weather effects. </li>
      <li> To date, this is the largest virtual dataset for person images.</li>
      <li> Paper: "WePerson: Learning a Generalized Re-identification Model from All-weather Virtual Data", ACM MM, 2021. <a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475455">PDF</a></li>
    </ul>


    <h4>Robust Deep Learning with Label Noise:&nbsp;<a href="https://github.com/mangye16/ReID-Label-Noise">Code</a></h4>
    <ul>
      <li> Robust deep learning under label noise (limited samples for each identity)</li>
      <li> Collaborative refining person re-identification model under label noise</li>
      <li> Online refining with hard instance re-weighting</li>
      <li> Paper: "PurifyNet: A Robust Person Re-identification Model with Noisy Labels", IEEE TIFS, 2020. <a href="https://ieeexplore.ieee.org/document/8976262">PDF</a></li>
      <li> Paper: "Collaborative Refining for Person Re-Identification with Label Noise", IEEE TIP, 2021.</li>
    </ul>


    <h3>Research Fundings</h3>
    <h4>主持科研项目：</h4>
    <ul>
      <li>2022.01-2024.12 基于无监督学习的监控目标检索关键技术研究 湖北省重点研发计划 100万</li>
      <li>2022.01-2025.12 面向复杂多变场景的行人重识别关键技术研究 国家自然科学基金（面上项目） 59万</li>
      <li>2021.02-2022.12 目标检测、跟踪与识别 中国科协青年人才托举项目 45万 </li>
      <li>2020.12-2021.11 开放环境下视觉学习理论及其应用 首届中国人工智能学会-华为 MindSpore学术奖励基金（B类） 18万 </li>
      <li>2021.11-2022.10 基于异构联邦学习的智能数据分类算法与框架  CCF-绿盟科技“鲲鹏”科研基金 8万</li>
      <li>2021.12-2022.11 开放场景下的监控目标检索关键技术研究 中国人工智能学会-华为 MindSpore学术奖励基金（B类） 18万 </li>
    </ul>

    <h3>Terms of Releasing Implementation: </h3>
    <p> Software provided here is for personal research purposes only. Redistribution and commercial usage are not
      permitted. Feedback, applications, and further development are welcome. Contact yemang AT whu.edu.cn for bugs and
      collaborations. All rights of the implementation are reserved by the authors.</p>


  </div>


  <script src="../static/jquery.js"></script>
  <script src="../static/bootstrap/js/bootstrap.js"></script>
</body>

</html>
